# Integration Test: Concurrent Tasks with Table Claiming
#
# This job tests that multiple concurrent tasks can safely process different tables
# while sharing the same control table. It validates the run_id and claim_table features.
#
# Test scenario:
# 1. setup_test_tables: Creates test tables
# 2. task_1 + task_2: Run concurrently with OVERLAPPING table_names
# 3. validate_results: Verifies each table was processed exactly once

resources:
  jobs:
    concurrent_tasks_test:
      name: "dbxmetagen_concurrent_tasks_test_${bundle.target}"

      email_notifications:
        on_failure:
          - ${var.current_user}

      parameters:
        - name: test_catalog
          default: "dev_integration_tests"
        - name: test_schema
          default: "dbxmetagen_tests"
        - name: run_id
          default: "{{run.id}}"

      tasks:
        # Step 1: Setup - create test tables
        - task_key: setup_test_tables
          job_cluster_key: test_cluster
          notebook_task:
            notebook_path: ../../notebooks/integration_tests/test_10_concurrent_setup.py
            base_parameters:
              test_catalog: "{{job.parameters.test_catalog}}"
              test_schema: "{{job.parameters.test_schema}}"
          libraries:
            - whl: ../../dist/*.whl

        # Step 2a: Concurrent task 1 - processes tables 1, 2, 3 (overlaps with task 2 on table 2)
        - task_key: concurrent_task_1
          depends_on:
            - task_key: setup_test_tables
          job_cluster_key: test_cluster
          notebook_task:
            notebook_path: ../../notebooks/generate_metadata.py
            base_parameters:
              mode: "comment"
              table_names: "{{job.parameters.test_catalog}}.{{job.parameters.test_schema}}.concurrent_test_1,{{job.parameters.test_catalog}}.{{job.parameters.test_schema}}.concurrent_test_2"
              catalog_name: "{{job.parameters.test_catalog}}"
              schema_name: "{{job.parameters.test_schema}}"
              cleanup_control_table: "false"
              run_id: "{{job.parameters.run_id}}"
              grant_permissions_after_creation: "false"
          libraries:
            - whl: ../../dist/*.whl

        # Step 2b: Concurrent task 2 - processes tables 2, 3, 4 (overlaps with task 1 on table 2)
        - task_key: concurrent_task_2
          depends_on:
            - task_key: setup_test_tables
          job_cluster_key: test_cluster
          notebook_task:
            notebook_path: ../../notebooks/generate_metadata.py
            base_parameters:
              mode: "comment"
              table_names: "{{job.parameters.test_catalog}}.{{job.parameters.test_schema}}.concurrent_test_2,{{job.parameters.test_catalog}}.{{job.parameters.test_schema}}.concurrent_test_3"
              catalog_name: "{{job.parameters.test_catalog}}"
              schema_name: "{{job.parameters.test_schema}}"
              cleanup_control_table: "false"
              run_id: "{{job.parameters.run_id}}"
              grant_permissions_after_creation: "false"
          libraries:
            - whl: ../../dist/*.whl

        # Step 3: Validate - check control table and logs
        - task_key: validate_results
          depends_on:
            - task_key: concurrent_task_1
            - task_key: concurrent_task_2
          job_cluster_key: test_cluster
          notebook_task:
            notebook_path: ../../notebooks/integration_tests/test_10_concurrent_validate.py
            base_parameters:
              test_catalog: "{{job.parameters.test_catalog}}"
              test_schema: "{{job.parameters.test_schema}}"
              run_id: "{{job.parameters.run_id}}"
          libraries:
            - whl: ../../dist/*.whl

      job_clusters:
        - job_cluster_key: test_cluster
          new_cluster:
            spark_version: 15.4.x-cpu-ml-scala2.12
            node_type_id: Standard_D3_v2
            num_workers: 0
            data_security_mode: SINGLE_USER
            spark_conf:
              spark.databricks.cluster.profile: singleNode
              spark.master: local[*]
            custom_tags:
              ResourceClass: SingleNode

