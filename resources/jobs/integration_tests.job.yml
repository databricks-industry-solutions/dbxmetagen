# Integration Tests Job Definition
#
# This job is COMMENTED OUT by default in databricks.yml to avoid cluttering
# workspace deployments. To use integration tests:
#   1. Uncomment the line in databricks.yml: "- resources/jobs/integration_tests.job.yml"
#   2. Run: ./scripts/run_integration_tests.sh
#
# See notebooks/integration_tests/README.md for full documentation.

resources:
  jobs:
    integration_tests:
      name: "dbxmetagen_integration_tests_${bundle.target}"

      email_notifications:
        on_failure:
          - ${var.current_user}

      parameters:
        - name: test_catalog
          default: "dev_integration_tests"
        - name: test_schema
          default: "dbxmetagen_tests"

      tasks:
        - task_key: test_01_widget_parsing
          job_cluster_key: integration_test_cluster
          notebook_task:
            notebook_path: ../../notebooks/integration_tests/test_01_widget_parsing.py
            base_parameters:
              test_catalog: "{{job.parameters.test_catalog}}"
              test_schema: "{{job.parameters.test_schema}}"
          libraries:
            - whl: ../../dist/*.whl

        - task_key: test_02_apply_ddl_false
          depends_on:
            - task_key: test_01_widget_parsing
          job_cluster_key: integration_test_cluster
          notebook_task:
            notebook_path: ../../notebooks/integration_tests/test_02_apply_ddl_false.py
            base_parameters:
              test_catalog: "{{job.parameters.test_catalog}}"
              test_schema: "{{job.parameters.test_schema}}"
          libraries:
            - whl: ../../dist/*.whl

        - task_key: test_03_apply_ddl_true
          depends_on:
            - task_key: test_02_apply_ddl_false
          job_cluster_key: integration_test_cluster
          notebook_task:
            notebook_path: ../../notebooks/integration_tests/test_03_apply_ddl_true.py
            base_parameters:
              test_catalog: "{{job.parameters.test_catalog}}"
              test_schema: "{{job.parameters.test_schema}}"
          libraries:
            - whl: ../../dist/*.whl

        - task_key: test_04_modes
          depends_on:
            - task_key: test_03_apply_ddl_true
          job_cluster_key: integration_test_cluster
          notebook_task:
            notebook_path: ../../notebooks/integration_tests/test_04_modes.py
            base_parameters:
              test_catalog: "{{job.parameters.test_catalog}}"
              test_schema: "{{job.parameters.test_schema}}"
          libraries:
            - whl: ../../dist/*.whl

        - task_key: test_05_temp_table_cleanup
          depends_on:
            - task_key: test_04_modes
          job_cluster_key: integration_test_cluster
          notebook_task:
            notebook_path: ../../notebooks/integration_tests/test_05_temp_table_cleanup.py
            base_parameters:
              test_catalog: "{{job.parameters.test_catalog}}"
              test_schema: "{{job.parameters.test_schema}}"
          libraries:
            - whl: ../../dist/*.whl

        - task_key: test_06_control_table
          depends_on:
            - task_key: test_05_temp_table_cleanup
          job_cluster_key: integration_test_cluster
          notebook_task:
            notebook_path: ../../notebooks/integration_tests/test_06_control_table.py
            base_parameters:
              test_catalog: "{{job.parameters.test_catalog}}"
              test_schema: "{{job.parameters.test_schema}}"
          libraries:
            - whl: ../../dist/*.whl

        - task_key: test_07_permissions
          depends_on:
            - task_key: test_06_control_table
          job_cluster_key: integration_test_cluster
          notebook_task:
            notebook_path: ../../notebooks/integration_tests/test_07_permissions.py
            base_parameters:
              test_catalog: "{{job.parameters.test_catalog}}"
              test_schema: "{{job.parameters.test_schema}}"
          libraries:
            - whl: ../../dist/*.whl

        # E2E tests run in parallel (no dependencies) to test different cluster configurations
        - task_key: test_e2e_serverless
          job_cluster_key: e2e_serverless_cluster
          notebook_task:
            notebook_path: ../../notebooks/integration_tests/test_e2e_serverless.py
            base_parameters:
              test_catalog: "{{job.parameters.test_catalog}}"
              test_schema: "{{job.parameters.test_schema}}"
          libraries:
            - whl: ../../dist/*.whl

        - task_key: test_e2e_ml_cluster
          job_cluster_key: e2e_ml_cluster
          notebook_task:
            notebook_path: ../../notebooks/integration_tests/test_e2e_ml_cluster.py
            base_parameters:
              test_catalog: "{{job.parameters.test_catalog}}"
              test_schema: "{{job.parameters.test_schema}}"
          libraries:
            - whl: ../../dist/*.whl

        - task_key: test_e2e_standard_cluster
          job_cluster_key: e2e_standard_cluster
          notebook_task:
            notebook_path: ../../notebooks/integration_tests/test_e2e_standard_cluster.py
            base_parameters:
              test_catalog: "{{job.parameters.test_catalog}}"
              test_schema: "{{job.parameters.test_schema}}"
          libraries:
            - whl: ../../dist/*.whl

      job_clusters:
        - job_cluster_key: integration_test_cluster
          new_cluster:
            spark_version: 15.4.x-cpu-ml-scala2.12
            node_type_id: Standard_D3_v2
            num_workers: 0
            data_security_mode: SINGLE_USER
            spark_conf:
              spark.databricks.cluster.profile: singleNode
              spark.master: local[*]
            custom_tags:
              ResourceClass: SingleNode

        # E2E test clusters for different runtime configurations
        - job_cluster_key: e2e_serverless_cluster
          new_cluster:
            spark_version: 15.4.x-photon-scala2.12
            node_type_id: Standard_D3_v2
            num_workers: 1
            data_security_mode: SINGLE_USER

        - job_cluster_key: e2e_ml_cluster
          new_cluster:
            spark_version: 15.4.x-cpu-ml-scala2.12
            node_type_id: Standard_D3_v2
            num_workers: 0
            data_security_mode: SINGLE_USER
            spark_conf:
              spark.databricks.cluster.profile: singleNode
              spark.master: local[*]
            custom_tags:
              ResourceClass: SingleNode

        - job_cluster_key: e2e_standard_cluster
          new_cluster:
            spark_version: 16.4.x-scala2.12
            node_type_id: Standard_D3_v2
            num_workers: 0
            data_security_mode: USER_ISOLATION
            spark_conf:
              spark.databricks.cluster.profile: singleNode
              spark.master: local[*]
            custom_tags:
              ResourceClass: SingleNode
